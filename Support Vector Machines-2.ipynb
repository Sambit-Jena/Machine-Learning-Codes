{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64448965-a7f2-42dc-b425-5a616367b40b",
   "metadata": {},
   "source": [
    "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575f7c4-9840-435c-b985-cde590a6d920",
   "metadata": {},
   "source": [
    "Polynomial functions and kernel functions are both used in machine learning algorithms, especially in support vector machines (SVMs). They have different roles and properties, but they are related in some ways.\n",
    "\n",
    "A polynomial function is a mathematical function that can be expressed as a sum of powers of one or more variables. For example, $f(x) = x^2 + 2x + 1$ is a polynomial function of degree. A polynomial function can be used to model linear or non-linear relationships between variables, such as the output of a regression model.\n",
    "\n",
    "A kernel function is a function that measures the similarity or distance between two vectors, usually in a high-dimensional feature space. For example, the Gaussian kernel function is defined as $k(x, y) = \\exp(-\\frac{\\|x - y\\|^2}{2\\sigma^2})$, where $\\sigma$ is a parameter that controls the width of the kernel. A kernel function can be used to map the input data into a feature space where a linear classifier or regressor can be applied, such as in SVMs.\n",
    "\n",
    "The relationship between polynomial functions and kernel functions is that a polynomial function can be used as a kernel function, but not vice versa. A polynomial kernel function is a kernel function that represents the similarity of vectors in a feature space over polynomials of the original variables. For example, the polynomial kernel function of degree $d$ is defined as $k(x, y) = (x \\cdot y + c)^d$, where $c$ is a parameter that controls the bias of the kernel. A polynomial kernel function can capture non-linear patterns in the data by transforming it into a higher-degree polynomial.\n",
    "\n",
    "However, a kernel function is not necessarily a polynomial function, because it does not have to follow the rules of polynomial arithmetic. For example, the Gaussian kernel function is not a polynomial function, because it involves an exponential function. A kernel function can be any function that satisfies some properties, such as being symmetric, positive definite, and continuous.\n",
    "\n",
    "Therefore, polynomial functions and kernel functions are related, but not equivalent, concepts in machine learning algorithms. They both can be used to model complex data, but they have different advantages and disadvantages. For more information, you can refer to the following sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d61c7-5f2e-4563-b3c3-e7d9aed95ea7",
   "metadata": {},
   "source": [
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cd6db0-64f9-4698-838d-33149e492a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate some random data for classification\n",
    "X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1643c4-77fd-4b49-b68c-4316b2b363f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=4, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=4, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(degree=4, kernel='poly')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the SVC class with a polynomial kernel of degree 4\n",
    "clf = SVC(kernel='poly', degree=4)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27039ce6-ab91-4149-9226-fdcabc363397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance using accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b38ef-c3ce-4c7d-81ff-f4fbc3149621",
   "metadata": {},
   "source": [
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ebb98-ab22-4463-9e81-924a2669feb8",
   "metadata": {},
   "source": [
    "Support vector regression (SVR) is a machine learning technique that aims to find a function that best fits a given set of data points, while allowing some errors within a specified margin. The margin is defined by a parameter called epsilon, which represents the acceptable error within the margin. Data points that lie within the margin or inside the epsilon tube are considered support vectors and do not contribute to the error.\n",
    "\n",
    "Increasing the value of epsilon means increasing the size of the margin or the tube, which allows more data points to be considered as support vectors. This reduces the number of data points that violate the margin constraints and are penalized by the cost function. Therefore, increasing epsilon generally decreases the number of support vectors in SVR, as long as the cost parameter C is fixed.\n",
    "\n",
    "However, if C is also increased, then the penalty for violating the margin constraints becomes higher, which may increase the number of support vectors in SVR. Therefore, the effect of epsilon on the number of support vectors depends on the trade-off between the margin size and the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84fbbe-5574-42aa-abde-77ed8a6149c2",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22378d-faa9-4a67-a18f-48934dc7fb66",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR) is a machine learning technique that can be used to fit a function to a set of data points. SVR tries to find a function that minimizes the error between the predicted and actual values, while also ensuring that the error does not exceed a certain threshold (epsilon). SVR can use different types of kernel functions to transform the input data into a higher-dimensional space, where it is easier to find a suitable function. The choice of kernel function, C parameter, epsilon parameter, and gamma parameter can affect the performance of SVR in different ways. Here is a brief explanation of each parameter and some examples of when you might want to adjust them:\n",
    "\n",
    "- **Kernel function**: This is the function that maps the input data to a higher-dimensional space. There are several types of kernel functions, such as linear, polynomial, radial basis function (RBF), sigmoid, etc. The choice of kernel function depends on the nature of the data and the complexity of the function you want to fit. For example, if the data is linearly separable, you can use a linear kernel. If the data is nonlinear, you can use a polynomial or RBF kernel. If the data is very complex, you can use a sigmoid kernel.\n",
    "- **C parameter**: This is the regularization parameter that controls the trade-off between the complexity of the function and the error tolerance. A higher C value means that the function will try to fit the data more closely, but it may also overfit the data and have poor generalization. A lower C value means that the function will be more smooth and simple, but it may also underfit the data and have high bias. The optimal C value depends on the amount of noise and outliers in the data. For example, if the data is noisy or has many outliers, you might want to use a lower C value to avoid overfitting. If the data is clean and has few outliers, you might want to use a higher C value to capture the underlying pattern.\n",
    "- **Epsilon parameter**: This is the error tolerance parameter that defines the width of the tube around the function. The tube is the region where the error between the predicted and actual values is less than or equal to epsilon. SVR tries to find a function that minimizes the number of points outside the tube, while also minimizing the magnitude of the error for those points. A higher epsilon value means that the tube will be wider, and the function will be more tolerant to errors. A lower epsilon value means that the tube will be narrower, and the function will be more sensitive to errors. The optimal epsilon value depends on the desired accuracy and precision of the predictions. For example, if you want to have more accurate predictions, you might want to use a lower epsilon value to reduce the error. If you want to have more robust predictions, you might want to use a higher epsilon value to avoid overfitting.\n",
    "- **Gamma parameter**: This is the kernel coefficient parameter that affects the shape and smoothness of the kernel function. A higher gamma value means that the kernel function will have a sharper peak and a faster decay, and the function will be more influenced by the nearby points. A lower gamma value means that the kernel function will have a flatter peak and a slower decay, and the function will be more influenced by the distant points. The optimal gamma value depends on the scale and distribution of the data. For example, if the data is sparse or has a large range, you might want to use a higher gamma value to capture the local variations. If the data is dense or has a small range, you might want to use a lower gamma value to capture the global trends.\n",
    "\n",
    "To find the best combination of these parameters for a given data set, you can use techniques such as grid search, cross-validation, or Bayesian optimization. These techniques can help you evaluate the performance of different parameter settings and select the one that maximizes a certain metric, such as mean squared error, R-squared, or coefficient of determination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6719149-8071-4fc2-af12-ab4a8d423e91",
   "metadata": {},
   "source": [
    "## Q5. Assignment:\n",
    "### Import the necessary libraries and load the dataseg\n",
    "### Split the dataset into training and testing setZ\n",
    "### Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "### Create an instance of the SVC classifier and train it on the training datW\n",
    "### hse the trained classifier to predict the labels of the testing datW\n",
    "### Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-scoreK\n",
    "### Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performanc_\n",
    "### Train the tuned classifier on the entire dataseg\n",
    "### Save the trained classifier to a file for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f7a68c-07b2-4e47-a41a-4471f924bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1331a0-0c27-476a-98b6-eab7147b7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = data.iloc[:,:-1]\n",
    "y=data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc340b4-fb1e-4b1b-86f0-438f2e53ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0154b9d3-94e2-4151-a783-8db5a4468a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68366ed-290b-4f1c-82ec-383318a5a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7337662337662337\n",
      "Precision: 0.7279593441150045\n",
      "Recall: 0.7337662337662337\n",
      "F1 Score: 0.7292649098474341\n"
     ]
    }
   ],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0fcc37-22ff-46e2-a177-11e8dddb0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.699 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.779 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.691 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.789 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.740 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.732 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.691 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.813 total time=   0.2s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.732 total time=   0.3s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.770 total time=   0.3s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.691 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.813 total time=   0.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.732 total time=   0.3s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.770 total time=   0.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.754 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.813 total time=   0.2s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.732 total time=   0.3s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.770 total time=   0.3s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.756 total time=   0.4s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.813 total time=   0.2s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.748 total time=   0.3s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.732 total time=   0.3s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.770 total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_svc_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103d2680-faee-4329-8c4a-ed4a1b145816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "best_svc_classifier.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f034e60a-883a-42af-9be6-1ce03fa57084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_classifier.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained classifier to a file\n",
    "joblib.dump(best_svc_classifier, 'trained_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
